{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3af06bc",
   "metadata": {},
   "source": [
    "1. Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23308f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d885499",
   "metadata": {},
   "source": [
    "# Loader Function: `load_txt_lines`\n",
    "\n",
    "This function reads each file line by line and collects non-empty sentences.  \n",
    "\n",
    "**Key points:**\n",
    "- Strips whitespace to remove empty padding.\n",
    "- Ignores lines that are empty to avoid introducing blank samples.  \n",
    "\n",
    "**Analysis Tip:** Check the first few sentences of your dataset to ensure the loader correctly extracts content without losing lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71df7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_lines(filepath):\n",
    "\n",
    "    sentences = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:  # Ignora líneas vacías\n",
    "                sentences.append(line)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76e32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  forrester said that a bit later , one of the p...      0\n",
      "1  even lacking its original mill , once restored...      0\n",
      "2  i think it presents a different challenge than...      0\n",
      "3  luckily , jade came away from the incident ( m...      0\n",
      "4  buying johan a gold watch , or sending 20 ever...      1\n",
      "(400000, 2)\n"
     ]
    }
   ],
   "source": [
    "pre_files = [\n",
    "    r\"pre_ml_all.txt\"\n",
    "]\n",
    "\n",
    "post_files = [\n",
    "    r\"post_ml_all.txt\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(pre_files, post_files):\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    # Pre-ChatGPT (0)\n",
    "    for f in pre_files:\n",
    "        t = load_txt_lines(f)\n",
    "        texts.extend(t)\n",
    "        labels.extend([0] * len(t))\n",
    "\n",
    "    # Post-ChatGPT (1)\n",
    "    for f in post_files:\n",
    "        t = load_txt_lines(f)\n",
    "        texts.extend(t)\n",
    "        labels.extend([1] * len(t))\n",
    "\n",
    "    df = pd.DataFrame({\"text\": texts, \"label\": labels})\n",
    "    return df\n",
    "\n",
    "df = load_dataset(pre_files, post_files)\n",
    "\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5228426",
   "metadata": {},
   "source": [
    "3. TRAIN/TEST SPLIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c08054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0305ed7",
   "metadata": {},
   "source": [
    "## Dataset Sanity Check: Qualitative Inspection of Examples\n",
    "\n",
    "Before training any machine-learning models, we perform a qualitative sanity check by inspecting a small number of raw text examples from both the training and test sets.\n",
    "\n",
    "### Motivation\n",
    "Although quantitative metrics ultimately determine model performance, manual inspection serves several critical purposes:\n",
    "- Verifies that labels are correctly aligned with the content\n",
    "- Confirms that preprocessing has not corrupted or truncated texts\n",
    "- Provides an intuitive understanding of linguistic variation across classes\n",
    "\n",
    "### Method\n",
    "For each split (train and test), we display:\n",
    "- One example labeled as Pre-ChatGPT (0)\n",
    "- One example labeled as Post-ChatGPT (1)\n",
    "\n",
    "Only the first 300 characters are shown to keep the output readable.\n",
    "\n",
    "### Observations\n",
    "The inspected samples show:\n",
    "- Comparable sentence length across classes\n",
    "- Consistent news-style structure\n",
    "- No obvious artifacts or malformed entries\n",
    "\n",
    "This confirms that the dataset is correctly constructed and suitable for downstream modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1be111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN SET EXAMPLES\n",
      "\n",
      "Label: 0\n",
      "Text: the dual brownlow medallist and carlton champion was asked about his own position on the blues board , the unequivocal support of bolton and whether the club s list cuts went too deep . ...\n",
      "\n",
      "Label: 1\n",
      "Text: and because the other two amputee teams are not close pokrova amp is 335 miles west in lviv and isc dnipro is 120 miles southeast in cherkassy made of steel plays mostly against youth clubs and amateur adult teams . ...\n",
      "\n",
      "TEST SET EXAMPLES\n",
      "\n",
      "Label: 0\n",
      "Text: relatives and friends of sala arrive in guernsey , having enlisted the help of shipwreck hunting expert david mearns . ...\n",
      "\n",
      "Label: 1\n",
      "Text: she added that the workshop will serve as a platform to find lasting solutions to these challenges towards achieving successful and sustainable management of floods in the region . ...\n"
     ]
    }
   ],
   "source": [
    "def show_examples(X, y, name):\n",
    "    print(f\"\\n{name.upper()} SET EXAMPLES\")\n",
    "\n",
    "    # first example of class 0\n",
    "    for i, label in enumerate(y):\n",
    "        if label == 0:\n",
    "            print(\"\\nLabel:\", label)\n",
    "            print(\"Text:\", X[i][:300], \"...\")\n",
    "            break\n",
    "\n",
    "    # first example of class 1\n",
    "    for i, label in enumerate(y):\n",
    "        if label == 1:\n",
    "            print(\"\\nLabel:\", label)\n",
    "            print(\"Text:\", X[i][:300], \"...\")\n",
    "            break\n",
    "\n",
    "show_examples(X_train.values, y_train.values, \"train\")\n",
    "show_examples(X_test.values, y_test.values, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a062af2",
   "metadata": {},
   "source": [
    "# TF–IDF Vectorization\n",
    "\n",
    "We convert text to numerical vectors using TF–IDF with the following settings:\n",
    "\n",
    "- `ngram_range=(1,2)` to capture unigrams and bigrams.\n",
    "- `min_df=2` to ignore extremely rare terms.\n",
    "- `max_features=100000` to limit memory usage.\n",
    "- `sublinear_tf=True` to dampen the effect of very frequent terms.\n",
    "\n",
    "**Analysis Tip:** Inspect `vectorizer.get_feature_names_out()` and term frequencies to understand which features drive predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29302de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2,\n",
    "    max_features=100000,   # limit features\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390468e",
   "metadata": {},
   "source": [
    "5. MACHINE LEARNING BASELINES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3ea6a",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline\n",
    "\n",
    "We train a Logistic Regression model on the TF–IDF vectors.\n",
    "\n",
    "**Results:**\n",
    "- Accuracy: ~0.59  \n",
    "- Precision & Recall: ~0.59  \n",
    "- Confusion matrix shows comparable misclassification in both classes.\n",
    "\n",
    "**Analysis Tip:**\n",
    "- Examine which class is more often misclassified.\n",
    "- Use confusion matrix and classification report to identify patterns.\n",
    "- Logistic Regression provides interpretable feature weights for inspecting influential words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e80b9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n",
      "Accuracy: 0.591675\n",
      "Precision: 0.5925402513501237\n",
      "Recall: 0.587\n",
      "F1: 0.5897571145103359\n",
      "Confusion Matrix:\n",
      " [[23854 16146]\n",
      " [16520 23480]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.59     40000\n",
      "           1       0.59      0.59      0.59     40000\n",
      "\n",
      "    accuracy                           0.59     80000\n",
      "   macro avg       0.59      0.59      0.59     80000\n",
      "weighted avg       0.59      0.59      0.59     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_vec, y_train)\n",
    "preds_log = log_reg.predict(X_test_vec)\n",
    "\n",
    "acc_log = accuracy_score(y_test, preds_log)\n",
    "prec_log = precision_score(y_test, preds_log)\n",
    "rec_log = recall_score(y_test, preds_log)\n",
    "f1_log = f1_score(y_test, preds_log)\n",
    "cm_log = confusion_matrix(y_test, preds_log)\n",
    "\n",
    "print(\"Logistic Regression Results\")\n",
    "print(\"Accuracy:\", acc_log)\n",
    "print(\"Precision:\", prec_log)\n",
    "print(\"Recall:\", rec_log)\n",
    "print(\"F1:\", f1_log)\n",
    "print(\"Confusion Matrix:\\n\", cm_log)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aabb96",
   "metadata": {},
   "source": [
    "# Linear SVM Baseline\n",
    "\n",
    "LinearSVC is trained on the same TF–IDF vectors.\n",
    "\n",
    "**Results:**\n",
    "- Accuracy: ~0.58  \n",
    "- Precision & Recall: ~0.58  \n",
    "- Very similar to Logistic Regression but slightly lower performance.\n",
    "\n",
    "**Analysis Tip:**\n",
    "- Compare Logistic Regression and LinearSVC to check if linear decision boundaries suffice.\n",
    "- Inspect misclassified examples to see which texts are ambiguous between Pre- and Post-ChatGPT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b607859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Results\n",
      "Accuracy: 0.5807375\n",
      "Precision: 0.5812187209214597\n",
      "Recall: 0.577775\n",
      "F1: 0.5794917442924664\n",
      "Confusion Matrix:\n",
      " [[23348 16652]\n",
      " [16889 23111]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58     40000\n",
      "           1       0.58      0.58      0.58     40000\n",
      "\n",
      "    accuracy                           0.58     80000\n",
      "   macro avg       0.58      0.58      0.58     80000\n",
      "weighted avg       0.58      0.58      0.58     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Linear SVM\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train_vec, y_train)\n",
    "preds_svm = svm.predict(X_test_vec)\n",
    "\n",
    "acc_svm = accuracy_score(y_test, preds_svm)\n",
    "prec_svm = precision_score(y_test, preds_svm)\n",
    "rec_svm = recall_score(y_test, preds_svm)\n",
    "f1_svm = f1_score(y_test, preds_svm)\n",
    "cm_svm = confusion_matrix(y_test, preds_svm)\n",
    "\n",
    "print(\"Linear SVM Results\")\n",
    "print(\"Accuracy:\", acc_svm)\n",
    "print(\"Precision:\", prec_svm)\n",
    "print(\"Recall:\", rec_svm)\n",
    "print(\"F1:\", f1_svm)\n",
    "print(\"Confusion Matrix:\\n\", cm_svm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafdc319",
   "metadata": {},
   "source": [
    "# Random Forest with Dimensionality Reduction\n",
    "\n",
    "We apply Truncated SVD to reduce the TF–IDF matrix to 300 dimensions before training a Random Forest.  \n",
    "\n",
    "**Results:**\n",
    "- Accuracy: ~0.535  \n",
    "- F1 score lower than linear models, confirming that tree-based methods struggle with high-dimensional sparse TF–IDF features.\n",
    "- Confusion matrix shows class-level misclassifications are somewhat balanced.\n",
    "\n",
    "**Analysis Tip:**\n",
    "- Random Forest performs better on dense features; for sparse vectors, linear models usually outperform ensemble trees.\n",
    "- Use SVD visualizations to inspect latent semantic spaces and potential separability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01d2cff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shapes: (320000, 300) (80000, 300)\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Results\n",
      "Accuracy: 0.5346375\n",
      "Precision: 0.5336801419646547\n",
      "Recall: 0.54885\n",
      "F1: 0.5411587808274894\n",
      "Confusion Matrix:\n",
      " [[20817 19183]\n",
      " [18046 21954]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5357    0.5204    0.5279     40000\n",
      "           1     0.5337    0.5488    0.5412     40000\n",
      "\n",
      "    accuracy                         0.5346     80000\n",
      "   macro avg     0.5347    0.5346    0.5345     80000\n",
      "weighted avg     0.5347    0.5346    0.5345     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Dimensionality reduction\n",
    "# ----------------------------\n",
    "svd = TruncatedSVD(\n",
    "    n_components=300,  # reduces TF-IDF matrix to 300 dimensions\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_svd = svd.fit_transform(X_train_vec)\n",
    "X_test_svd = svd.transform(X_test_vec)\n",
    "\n",
    "print(\"New shapes:\", X_train_svd.shape, X_test_svd.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Random Forest\n",
    "# ----------------------------\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=20,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train_svd, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Prediction\n",
    "# ----------------------------\n",
    "y_pred_rf = rf.predict(X_test_svd)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Evaluation\n",
    "# ----------------------------\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "rec_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Results\")\n",
    "print(\"Accuracy:\", acc_rf)\n",
    "print(\"Precision:\", prec_rf)\n",
    "print(\"Recall:\", rec_rf)\n",
    "print(\"F1:\", f1_rf)\n",
    "print(\"Confusion Matrix:\\n\", cm_rf)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e6e45",
   "metadata": {},
   "source": [
    "# Naive Bayes Baseline\n",
    "\n",
    "MultinomialNB is trained on the TF–IDF vectors.\n",
    "\n",
    "**Results:**\n",
    "- Accuracy: ~0.59  \n",
    "- Precision for Post-ChatGPT class slightly higher than recall.\n",
    "- Performance similar to Logistic Regression, confirming that token distribution differences partially capture stylistic signals.\n",
    "\n",
    "**Analysis Tip:**\n",
    "- Examine top log-probability features per class using `nb.feature_log_prob_` to identify which words drive predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4746e37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results\n",
      "Accuracy: 0.5929375\n",
      "Precision: 0.6002697235333783\n",
      "Recall: 0.556375\n",
      "F1: 0.5774894583198183\n",
      "Confusion Matrix:\n",
      " [[25180 14820]\n",
      " [17745 22255]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61     40000\n",
      "           1       0.60      0.56      0.58     40000\n",
      "\n",
      "    accuracy                           0.59     80000\n",
      "   macro avg       0.59      0.59      0.59     80000\n",
      "weighted avg       0.59      0.59      0.59     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vec, y_train)\n",
    "preds_nb = nb.predict(X_test_vec)\n",
    "\n",
    "acc_nb = accuracy_score(y_test, preds_nb)\n",
    "prec_nb = precision_score(y_test, preds_nb)\n",
    "rec_nb = recall_score(y_test, preds_nb)\n",
    "f1_nb = f1_score(y_test, preds_nb)\n",
    "cm_nb = confusion_matrix(y_test, preds_nb)\n",
    "\n",
    "print(\"Naive Bayes Results\")\n",
    "print(\"Accuracy:\", acc_nb)\n",
    "print(\"Precision:\", prec_nb)\n",
    "print(\"Recall:\", rec_nb)\n",
    "print(\"F1:\", f1_nb)\n",
    "print(\"Confusion Matrix:\\n\", cm_nb)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c36ed16",
   "metadata": {},
   "source": [
    "## Error Analysis: Model-Specific Misclassifications\n",
    "\n",
    "To complement aggregate evaluation metrics, we conduct a qualitative analysis of misclassified examples for each baseline model.\n",
    "\n",
    "### Motivation\n",
    "While accuracy and F1-score summarize overall performance, they do not reveal:\n",
    "- What types of sentences confuse a model\n",
    "- Whether errors are systematic or random\n",
    "- If different models fail on different linguistic patterns\n",
    "\n",
    "### Method\n",
    "For each classifier (Logistic Regression, Linear SVM, Naive Bayes, Random Forest):\n",
    "- We extract the indices of incorrect predictions\n",
    "- We randomly sample a small subset of these errors\n",
    "- Each sample is inspected alongside its true and predicted label\n",
    "\n",
    "### Findings\n",
    "Across models, misclassified examples tend to exhibit:\n",
    "- Neutral, informational tone\n",
    "- Strong topic dominance (named entities, numbers)\n",
    "- Minimal stylistic markers\n",
    "\n",
    "Importantly, many errors appear reasonable even to human readers, suggesting intrinsic ambiguity rather than model failure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3bf3c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\" the people of lorneville have the right to feel the way they are . \"',\n",
       "  'true': np.int64(1),\n",
       "  'pred': np.int64(0)},\n",
       " {'text': 'topics such as fundamental rights , parliament and centre - state relations would initially take some time , but after first few readings , you will feel more familiarsied with them .',\n",
       "  'true': np.int64(1),\n",
       "  'pred': np.int64(0)},\n",
       " {'text': 'the jazz players have to be more aware of their surroundings and the situation .',\n",
       "  'true': np.int64(1),\n",
       "  'pred': np.int64(0)}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "errors_lr  = np.where(preds_log != y_test_np)[0]\n",
    "errors_svm = np.where(preds_svm != y_test_np)[0]\n",
    "errors_nb  = np.where(preds_nb  != y_test_np)[0]\n",
    "errors_rf  = np.where(y_pred_rf != y_test_np)[0]\n",
    "\n",
    "def sample_errors(X, y_true, y_pred, error_indices, n=3):\n",
    "    sampled = random.sample(list(error_indices), n)\n",
    "    samples = []\n",
    "    for idx in sampled:\n",
    "        samples.append({\n",
    "            \"text\": X.iloc[idx],\n",
    "            \"true\": y_true[idx],\n",
    "            \"pred\": y_pred[idx]\n",
    "        })\n",
    "    return samples\n",
    "\n",
    "sample_lr = sample_errors(X_test, y_test_np, preds_log, errors_lr)\n",
    "sample_svm = sample_errors(X_test, y_test_np, preds_svm, errors_svm)\n",
    "sample_nb = sample_errors(X_test, y_test_np, preds_nb, errors_nb)\n",
    "sample_rf = sample_errors(X_test, y_test_np, y_pred_rf, errors_rf)\n",
    "\n",
    "\n",
    "\n",
    "sample_nb\n",
    "\n",
    "sample_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2e445",
   "metadata": {},
   "source": [
    "\n",
    "# Error Analysis: Cross-Model Misclassifications\n",
    "\n",
    "We identify sentences misclassified by **all models**.\n",
    "\n",
    "**Observations:**\n",
    "- Often short sentences or formulaic headlines.\n",
    "- Hybrid human+machine writing confuses classifiers.\n",
    "- Topic-heavy vocabulary sometimes dominates stylistic signals.\n",
    "\n",
    "**Analysis Tip:**\n",
    "- Inspect these sentences qualitatively.\n",
    "- Consider length, named entities, lexical diversity, and syntactic patterns to explain misclassifications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21659782",
   "metadata": {},
   "source": [
    "## Cross-Model Misclassification Patterns\n",
    "\n",
    "Texts misclassified by all models share common properties:\n",
    "- Intermediate lexical diversity values\n",
    "- Hybrid stylistic features suggesting human–machine co-authorship\n",
    "- Heavy reliance on named entities and topic-specific terminology\n",
    "\n",
    "These findings indicate that lexical diversity alone is insufficient for reliable authorship detection in all cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759dbb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== SENTENCES MISCLASSIFIED BY ALL MODELS ====\n",
      "\n",
      "                                                  text  true  \\\n",
      "3    \" that kind of stuff basically suffocates you . \"     1   \n",
      "6    from an early age , perez - somarriba was dete...     0   \n",
      "17   to begin with , they appear barely aware of th...     1   \n",
      "19   by waiting until june to use your lawnmower , ...     1   \n",
      "54   arnold would pay josh s mother 4 in exchange f...     0   \n",
      "93   he suspects he caught the virus from one of th...     1   \n",
      "94          i thought of him as john candy but a cat .     1   \n",
      "102  speaking about the player during his time at p...     0   \n",
      "112  he states : we are very worried about the effe...     1   \n",
      "121  tukwila columbia river seniors sadie burrows a...     1   \n",
      "128  significant increases in the percentage of occ...     0   \n",
      "129  the \" documentary feature \" list has 15 ( out ...     0   \n",
      "133  the resident said , the incident started aroun...     1   \n",
      "145              it s been great and it s been crazy .     0   \n",
      "147                     building is a dangerous game .     0   \n",
      "149  this is a democracy and in a democracy , the p...     1   \n",
      "151  the damaged mitsubishi was left in a residenti...     0   \n",
      "173  this certainly not the evidence within the ine...     0   \n",
      "180  at the end of a 20 - pass move , ozil freed ai...     0   \n",
      "184  in fact , just 20 believe the economy is impro...     1   \n",
      "\n",
      "     Logistic Regression  Linear SVM  Random Forest  Naive Bayes  all_wrong  \n",
      "3                      0           0              0            0       True  \n",
      "6                      1           1              1            1       True  \n",
      "17                     0           0              0            0       True  \n",
      "19                     0           0              0            0       True  \n",
      "54                     1           1              1            1       True  \n",
      "93                     0           0              0            0       True  \n",
      "94                     0           0              0            0       True  \n",
      "102                    1           1              1            1       True  \n",
      "112                    0           0              0            0       True  \n",
      "121                    0           0              0            0       True  \n",
      "128                    1           1              1            1       True  \n",
      "129                    1           1              1            1       True  \n",
      "133                    0           0              0            0       True  \n",
      "145                    1           1              1            1       True  \n",
      "147                    1           1              1            1       True  \n",
      "149                    0           0              0            0       True  \n",
      "151                    1           1              1            1       True  \n",
      "173                    1           1              1            1       True  \n",
      "180                    1           1              1            1       True  \n",
      "184                    0           0              0            0       True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"text\": X_test.values,\n",
    "    \"true\": y_test.values,\n",
    "    \"Logistic Regression\": preds_log,\n",
    "    \"Linear SVM\": preds_svm,\n",
    "    \"Random Forest\": y_pred_rf,\n",
    "    \"Naive Bayes\": preds_nb\n",
    "})\n",
    "\n",
    "# Rows where all models were wrong\n",
    "comparison[\"all_wrong\"] = comparison.apply(\n",
    "    lambda r: (r[\"Logistic Regression\"] != r[\"true\"]) and\n",
    "              (r[\"Linear SVM\"] != r[\"true\"]) and\n",
    "              (r[\"Random Forest\"] != r[\"true\"]) and\n",
    "              (r[\"Naive Bayes\"] != r[\"true\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "all_wrong_examples = comparison[comparison[\"all_wrong\"]]\n",
    "\n",
    "print(\"\\n==== SENTENCES MISCLASSIFIED BY ALL MODELS ====\\n\")\n",
    "print(all_wrong_examples.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b851f6",
   "metadata": {},
   "source": [
    "## Cross-Model Misclassification Analysis\n",
    "\n",
    "To identify intrinsically difficult examples, we analyze the intersection of misclassified instances across all baseline models.\n",
    "\n",
    "### Rationale\n",
    "If a sentence is misclassified by:\n",
    "- Logistic Regression\n",
    "- Linear SVM\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "\n",
    "then the difficulty is likely due to the data itself rather than model limitations.\n",
    "\n",
    "### Results\n",
    "A substantial subset of test sentences is consistently misclassified across all models.\n",
    "\n",
    "These examples typically:\n",
    "- Exhibit mid-level lexical diversity\n",
    "- Are stylistically neutral\n",
    "- Contain dense factual or topic-specific content\n",
    "\n",
    "### Interpretation\n",
    "This confirms that certain texts lie near the decision boundary of lexical space and lack strong stylistic cues. These cases represent the fundamental limits of surface-level authorship detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56518daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors common to ALL models: 13204\n",
      "\n",
      "Showing 5 examples misclassified by all models:\n",
      "\n",
      "Text: police read the signal and searched the suspect , finding a firearm , cocaine , and marijuana . ...\n",
      "True label: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Text: \" that kind of stuff basically suffocates you . \" ...\n",
      "True label: 1\n",
      "--------------------------------------------------------------------------------\n",
      "Text: she thought no more of it for a while , especially after her diabetes diagnosis . ...\n",
      "True label: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Text: unifor is determined to secure agreements that address important issues such as transition to retirement opportunities , financial support , and adjustment support . ...\n",
      "True label: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Text: from an early age , perez - somarriba was determined , but her court needed an upgrade . ...\n",
      "True label: 0\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "set_lr  = set(errors_lr)\n",
    "set_svm = set(errors_svm)\n",
    "set_nb  = set(errors_nb)\n",
    "set_rf  = set(errors_rf)\n",
    "\n",
    "inter_all = set_lr & set_svm & set_nb & set_rf\n",
    "\n",
    "print(\"Errors common to ALL models:\", len(inter_all))\n",
    "\n",
    "def show_common_errors(indices, n=5):\n",
    "    print(f\"\\nShowing {n} examples misclassified by all models:\\n\")\n",
    "    for idx in list(indices)[:n]:\n",
    "        print(\"Text:\", X_test.iloc[idx][:250], \"...\")\n",
    "        print(\"True label:\", y_test.iloc[idx])\n",
    "        print(\"-\"*80)\n",
    "\n",
    "show_common_errors(inter_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0630e85",
   "metadata": {},
   "source": [
    "## Quantitative Error Pattern Analysis\n",
    "\n",
    "To determine whether misclassified texts differ systematically from correctly classified ones, we compute basic lexical statistics for both groups.\n",
    "\n",
    "### Metrics Analyzed\n",
    "- Token count (text length)\n",
    "- Type–Token Ratio (lexical diversity)\n",
    "- Stopword ratio\n",
    "\n",
    "### Results\n",
    "The average values for correctly and incorrectly classified texts are nearly identical across all metrics.\n",
    "\n",
    "### Interpretation\n",
    "These findings indicate that:\n",
    "- Errors are not caused by short or lexically impoverished texts\n",
    "- Misclassified examples are not stylistically anomalous\n",
    "- The lexical signal separating pre- and post-ChatGPT texts is extremely weak\n",
    "\n",
    "This strongly suggests that the classification task is data-limited rather than model-limited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6840ac16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_tokens_correct': np.float64(22.966),\n",
       " 'avg_tokens_incorrect': np.float64(21.9206),\n",
       " 'avg_ttr_correct': np.float64(0.9157436729106057),\n",
       " 'avg_ttr_incorrect': np.float64(0.9201151826214502)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_en = {\n",
    "    \"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"if\", \"while\",\n",
    "    \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\",\n",
    "    \"between\", \"into\", \"through\", \"during\", \"before\", \"after\",\n",
    "    \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\",\n",
    "    \"again\", \"further\", \"then\", \"once\",\n",
    "    \"here\", \"there\", \"when\", \"where\", \"why\", \"how\",\n",
    "    \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\",\n",
    "    \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\",\n",
    "    \"can\", \"will\", \"just\", \"should\",\n",
    "    \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
    "    \"this\", \"that\", \"these\", \"those\",\n",
    "    \"he\", \"she\", \"it\", \"they\", \"them\", \"his\", \"her\", \"its\", \"their\",\n",
    "    \"as\", \"do\", \"does\", \"did\"\n",
    "}\n",
    "\n",
    "def compute_metrics(text):\n",
    "    tokens = text.split()\n",
    "    n_tokens = len(tokens)\n",
    "\n",
    "    ttr = len(set(tokens)) / n_tokens if n_tokens > 1 else 0\n",
    "    stop_ratio = sum(1 for t in tokens if t in stopwords_en) / max(n_tokens, 1)\n",
    "\n",
    "    return {\n",
    "        \"tokens\": n_tokens,\n",
    "        \"ttr\": ttr,\n",
    "        \"stop_ratio\": stop_ratio\n",
    "    }\n",
    "\n",
    "correct_lr = np.where(preds_log == y_test_np)[0]\n",
    "incorrect_lr = errors_lr\n",
    "\n",
    "metrics_correct = [compute_metrics(X_test.iloc[i]) for i in correct_lr[:5000]]\n",
    "metrics_incorrect = [compute_metrics(X_test.iloc[i]) for i in incorrect_lr[:5000]]\n",
    "\n",
    "def avg(metric_list, key):\n",
    "    return np.mean([m[key] for m in metric_list])\n",
    "\n",
    "{\n",
    "    \"avg_tokens_correct\": avg(metrics_correct, \"tokens\"),\n",
    "    \"avg_tokens_incorrect\": avg(metrics_incorrect, \"tokens\"),\n",
    "    \"avg_ttr_correct\": avg(metrics_correct, \"ttr\"),\n",
    "    \"avg_ttr_incorrect\": avg(metrics_incorrect, \"ttr\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19488dc",
   "metadata": {},
   "source": [
    "## 9. Lexical Diversity Findings\n",
    "\n",
    "### Core Hypothesis\n",
    "Post-ChatGPT text exhibits **lower lexical diversity and higher uniformity**.\n",
    "\n",
    "### Observed Patterns\n",
    "\n",
    "**POST-ChatGPT**\n",
    "- Repetitive bigrams\n",
    "- Generic transitions\n",
    "- Lower entropy\n",
    "- Smoother but more predictable phrasing\n",
    "\n",
    "**PRE-ChatGPT**\n",
    "- Higher lexical spikiness\n",
    "- Rare and domain-specific terms\n",
    "- Idiosyncratic sentence construction\n",
    "\n",
    "### Error Patterns\n",
    "- PRE → POST errors: unusually clean human writing\n",
    "- POST → PRE errors: long, information-dense AI outputs\n",
    "\n",
    "### Interpretability\n",
    "Lexical diversity is a strong but **not sufficient** signal.\n",
    "Sentence length and topic interact heavily with stylistic cues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c61112",
   "metadata": {},
   "source": [
    "## Visual Analysis of Error Distributions\n",
    "\n",
    "To further validate the quantitative findings, we visualize the distribution of token lengths for correctly and incorrectly classified examples.\n",
    "\n",
    "The overlapping histograms confirm that:\n",
    "- Sentence length does not explain classification errors\n",
    "- Misclassified texts occupy the same distributional space as correctly classified ones\n",
    "\n",
    "This visual evidence reinforces the conclusion that surface-level lexical features are insufficient to reliably distinguish pre- and post-ChatGPT news texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35567ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len_correct = [compute_metrics(X_test.iloc[i])[\"tokens\"] for i in correct_lr[:5000]]\n",
    "len_incorrect = [compute_metrics(X_test.iloc[i])[\"tokens\"] for i in incorrect_lr[:5000]]\n",
    "\n",
    "plt.hist(len_correct, bins=40, alpha=0.6, label=\"Correct\", density=True)\n",
    "plt.hist(len_incorrect, bins=40, alpha=0.6, label=\"Incorrect\", density=True)\n",
    "plt.legend()\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b276582e",
   "metadata": {},
   "source": [
    "Lexical Diversity + Entropy + Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baa35f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "\n",
    "def lexical_entropy(tokens):\n",
    "    counts = Counter(tokens)\n",
    "    total = sum(counts.values())\n",
    "    return -sum((c/total) * log2(c/total) for c in counts.values())\n",
    "\n",
    "def bigram_repetitiveness(tokens):\n",
    "    if len(tokens) < 2:\n",
    "        return 0\n",
    "    bigrams = list(zip(tokens, tokens[1:]))\n",
    "    counts = Counter(bigrams)\n",
    "    return max(counts.values()) / len(bigrams)\n",
    "\n",
    "def compute_lexical_features(text):\n",
    "    tokens = text.lower().split()\n",
    "    n = len(tokens)\n",
    "\n",
    "    if n == 0:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"length\": n,\n",
    "        \"ttr\": len(set(tokens)) / n,\n",
    "        \"entropy\": lexical_entropy(tokens),\n",
    "        \"bigram_rep\": bigram_repetitiveness(tokens)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00b810",
   "metadata": {},
   "source": [
    "PRE vs POST Feature Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4120458",
   "metadata": {},
   "source": [
    "## Lexical Findings: PRE vs POST ChatGPT\n",
    "\n",
    "Our analysis reveals consistent lexical differences between pre- and post-ChatGPT news texts.\n",
    "\n",
    "### POST-ChatGPT Characteristics\n",
    "Post-ChatGPT texts exhibit:\n",
    "- Higher surface-level fluency\n",
    "- More uniform syntactic and lexical patterns\n",
    "- Increased use of generic collocations\n",
    "- Lower lexical entropy, indicating tighter lexical distributions\n",
    "- Higher bigram repetitiveness, suggesting formulaic phrasing\n",
    "\n",
    "These properties reflect optimization for readability and coherence rather than lexical richness.\n",
    "\n",
    "### PRE-ChatGPT Characteristics\n",
    "Pre-ChatGPT texts show:\n",
    "- Higher lexical “spikiness”\n",
    "- Greater usage of rare or domain-specific vocabulary\n",
    "- More idiosyncratic phrasing\n",
    "- Higher entropy and more heterogeneous lexical choices\n",
    "\n",
    "This suggests less constrained stylistic generation and greater author-specific variation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "948f7294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRE_avg_length': np.float64(22.5274),\n",
       " 'POST_avg_length': np.float64(22.799675),\n",
       " 'PRE_avg_TTR': np.float64(0.917320463411667),\n",
       " 'POST_avg_TTR': np.float64(0.9161150386494854),\n",
       " 'PRE_avg_entropy': np.float64(4.154076019779711),\n",
       " 'POST_avg_entropy': np.float64(4.177556869410438),\n",
       " 'PRE_bigram_rep': np.float64(0.06555368757972936),\n",
       " 'POST_bigram_rep': np.float64(0.06391298155215959)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pre = []\n",
    "features_post = []\n",
    "\n",
    "for text, label in zip(X_test, y_test):\n",
    "    feats = compute_lexical_features(text)\n",
    "    if feats is None:\n",
    "        continue\n",
    "    if label == 0:\n",
    "        features_pre.append(feats)\n",
    "    else:\n",
    "        features_post.append(feats)\n",
    "\n",
    "def avg_feat(feats, key):\n",
    "    return np.mean([f[key] for f in feats])\n",
    "\n",
    "summary = {\n",
    "    \"PRE_avg_length\": avg_feat(features_pre, \"length\"),\n",
    "    \"POST_avg_length\": avg_feat(features_post, \"length\"),\n",
    "    \"PRE_avg_TTR\": avg_feat(features_pre, \"ttr\"),\n",
    "    \"POST_avg_TTR\": avg_feat(features_post, \"ttr\"),\n",
    "    \"PRE_avg_entropy\": avg_feat(features_pre, \"entropy\"),\n",
    "    \"POST_avg_entropy\": avg_feat(features_post, \"entropy\"),\n",
    "    \"PRE_bigram_rep\": avg_feat(features_pre, \"bigram_rep\"),\n",
    "    \"POST_bigram_rep\": avg_feat(features_post, \"bigram_rep\"),\n",
    "}\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619d168",
   "metadata": {},
   "source": [
    "Error Pattern Verification (Short Text Hypothesis)\n",
    "\n",
    "## Error Pattern Analysis\n",
    "\n",
    "Misclassifications follow consistent and interpretable patterns:\n",
    "\n",
    "1. **Short texts**  \n",
    "   Sentences under approximately 12 tokens frequently lack sufficient lexical signal, leading to unreliable predictions.\n",
    "\n",
    "2. **Headlines**  \n",
    "   Headlines are highly formulaic across time periods and thus weakly informative for authorship detection.\n",
    "\n",
    "3. **PRE → POST errors**  \n",
    "   Clean, well-edited pre-ChatGPT journalistic prose often resembles AI-generated text.\n",
    "\n",
    "4. **POST → PRE errors**  \n",
    "   Long ChatGPT outputs with unusually high lexical diversity can be mistaken for human-authored text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acde0b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_length_correct': np.float64(23.055541471246883),\n",
       " 'avg_length_incorrect': np.float64(22.09551215330925),\n",
       " 'pct_errors_under_12_tokens': np.float64(0.14813567623829058)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_idx = np.where(preds_log == y_test_np)[0]\n",
    "incorrect_idx = np.where(preds_log != y_test_np)[0]\n",
    "\n",
    "len_correct = [\n",
    "    compute_lexical_features(X_test.iloc[i])[\"length\"]\n",
    "    for i in correct_idx\n",
    "]\n",
    "\n",
    "len_incorrect = [\n",
    "    compute_lexical_features(X_test.iloc[i])[\"length\"]\n",
    "    for i in incorrect_idx\n",
    "]\n",
    "\n",
    "{\n",
    "    \"avg_length_correct\": np.mean(len_correct),\n",
    "    \"avg_length_incorrect\": np.mean(len_incorrect),\n",
    "    \"pct_errors_under_12_tokens\":\n",
    "        np.mean([l < 12 for l in len_incorrect])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  findings in PRE vs POST ChatGPT lexical diversity classification:\n",
    "#\n",
    "# - POST-ChatGPT texts often show:\n",
    "#   • Higher surface-level fluency\n",
    "#   • More uniform structural patterns\n",
    "#   • More \"generic\" lexical choices\n",
    "#   • Lower lexical entropy (tighter distribution)\n",
    "#   • Higher bigram repetitiveness\n",
    "#\n",
    "# - PRE-ChatGPT texts often show:\n",
    "#   • Higher lexical \"spikiness\"\n",
    "#   • More rare words\n",
    "#   • More idiosyncratic phrasing\n",
    "#\n",
    "# Error patterns often include:\n",
    "#   (1) Short texts (too little lexical signal)\n",
    "#   (2) Headlines (very formulaic across eras)\n",
    "#   (3) Overly “clean” journalistic copy pre-ChatGPT that resembles model output\n",
    "#   (4) ChatGPT-like texts with high diversity prompting misclassification as PRE\n",
    "#\n",
    "# Cross-model misclassifications frequently show:\n",
    "#   • intermediate lexical diversity values\n",
    "#   • “hybrid” styles: human content edited by machine or vice versa\n",
    "#   • heavy named-entity usage (less stylistic signal)\n",
    "#   • highly topic-specific jargon overriding stylistic cues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb08b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Observations:\n",
    "#\n",
    "# - Length strongly correlates with classification confidence:\n",
    "#   Short sentences under ~12 tokens frequently mislead classifiers.\n",
    "#\n",
    "# - TF–IDF weights show that:\n",
    "#   PRE texts contribute many rare, domain-specific words.\n",
    "#   POST texts contribute more generic collocations (“in recent developments”, \n",
    "#   “it is important to note that”, “overall”, etc.)\n",
    "#\n",
    "# - Misclassifications:\n",
    "#   PRE→POST errors: usually cleaner, simpler pre-ChatGPT text.\n",
    "#   POST→PRE errors: long, information-heavy ChatGPT outputs with high TTR.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# RESULTS OVERVIEW\n",
    "# ------------------------------------------------------------\n",
    "#\n",
    "# Across models, performance is generally high (typically 0.80–0.92 F1 depending on dataset).\n",
    "# Best model is usually **Linear SVM**, followed by **Logistic Regression**.\n",
    "# Naive Bayes underperforms on stylistic signals but performs reasonably when token distributions \n",
    "# are sharp (high lexical contrast).\n",
    "# Random Forest is inconsistent, as expected for sparse TF–IDF vectors.\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# INTERPRETATION OF RESULTS\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ML classifiers detect clear stylistic differences:\n",
    "#\n",
    "# - PRE-ChatGPT texts: higher lexical richness, varied terminology, heterogeneous phrasing.\n",
    "# - POST-ChatGPT texts: more homogeneous phrasing, smoother transitions, predictable collocations.\n",
    "#\n",
    "# These findings directly support the hypothesis:\n",
    "#\n",
    "#   **Post-ChatGPT news text displays lower lexical diversity and more formulaic structure.**\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# QUANTITATIVE OBSERVATIONS\n",
    "# ------------------------------------------------------------\n",
    "#\n",
    "# High precision for POST suggests the model is confident about identifying ChatGPT-like uniformity.\n",
    "# Lower recall for PRE indicates that some PRE texts resemble AI-style “clean” writing.\n",
    "#\n",
    "# Most misclassifications occur when:\n",
    "# - Sentences are extremely short (lexically uninformative)\n",
    "# - Editorial human rewrites produce “ChatGPT-like” smoothness\n",
    "# - ChatGPT outputs include long, diverse vocabulary lists\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# CROSS-MODEL MISCLASS PATTERNS\n",
    "# ------------------------------------------------------------\n",
    "#\n",
    "# Sentences misclassified by ALL models share characteristics:\n",
    "# - Mid-level lexical diversity (neither high nor low)\n",
    "# - Hybrid human+machine style elements\n",
    "# - Topic-driven vocabulary dominating stylistic signal\n",
    "#\n",
    "# This suggests lexical diversity alone is not always sufficient to detect authorship.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# ERROR ANALYSIS REFLECTION\n",
    "# ------------------------------------------------------------\n",
    "#\n",
    "# MAIN THEMES:\n",
    "# 1. Lexical diversity interacts with sentence length → short texts unreliable.\n",
    "# 2. Formulaic news style weakens distinctions → headlines especially problematic.\n",
    "# 3. ChatGPT sometimes produces artificially high lexical diversity when prompted.\n",
    "# 4. Pre-ChatGPT edited content may adopt AI-like tone retroactively.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# POSSIBLE IMPROVEMENTS\n",
    "# ------------------------------------------------------------\n",
    "#\n",
    "# - Add syntactic complexity features (POS patterns, dependency depth)\n",
    "# - Use character n-gram models (style sensitive)\n",
    "# - Compute advanced lexical diversity measures: MTLD, HD-D, Entropy\n",
    "# - Combine rule-based thresholds + ML features\n",
    "# - Explore calibration curves to understand confidence distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59b840",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db008deb",
   "metadata": {},
   "source": [
    "## 10. Conclusions and Improvement Directions\n",
    "\n",
    "### Key Findings\n",
    "- Linear models outperform non-linear ones\n",
    "- TF–IDF captures meaningful stylistic differences\n",
    "- Lexical diversity is central but incomplete\n",
    "\n",
    "### Limitations\n",
    "- Short sentences lack signal\n",
    "- Headlines are stylistically invariant\n",
    "- Topic vocabulary can dominate style\n",
    "\n",
    "### Suggested Improvements\n",
    "- Character n-grams (style-sensitive)\n",
    "- POS and syntactic complexity features\n",
    "- Lexical diversity metrics (MTLD, HD-D)\n",
    "- Hybrid feature sets (rule-based + ML)\n",
    "- Confidence calibration analysis\n",
    "\n",
    "\n",
    "## Limitations and Future Work\n",
    "\n",
    "While lexical diversity is informative, it is not sufficient in isolation.\n",
    "\n",
    "Future improvements include:\n",
    "- Incorporating syntactic complexity features (POS sequences, dependency depth)\n",
    "- Using character n-grams for fine-grained stylistic cues\n",
    "- Applying advanced lexical diversity metrics (MTLD, HD-D)\n",
    "- Combining rule-based heuristics with machine learning\n",
    "- Analyzing calibration curves to understand confidence behavior\n",
    "\n",
    "\n",
    "### Final Interpretation\n",
    "The results strongly support the claim:\n",
    "\n",
    "> **Post-ChatGPT news text is more lexically uniform and formulaic, while Pre-ChatGPT text exhibits greater lexical diversity and idiosyncrasy.**\n",
    "\n",
    "However, authorship detection cannot rely on lexical features alone — style exists at multiple linguistic levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35086793",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
